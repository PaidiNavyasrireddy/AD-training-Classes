# -*- coding: utf-8 -*-
"""day-15

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d0oN0gpxlQK3WzJIjZnhxaERx4YPtZGP
"""

import pandas as pd
import numpy as np
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df=sns.load_dataset('iris')
df

df.duplicated()

df.duplicated().sum()

df['species'].unique()

setosa 1
versi 2
virginioca 3

df['species'].replace({'setosa':1,'versicolor':2,'virginica':3},inplace=True)

df.info()

from sklearn.preprocessing import LabelEncoder
lb=LabelEncoder()
lb.fit_transform(df['species'])

df

df['species'].unique()

oh_species=pd.get_dummies(df['species'])
df=pd.concat([df.drop('species',axis=1),oh_species],axis=1)

df

from sklearn.ensemble import IsolationForest
import seaborn as sns
import pandas as pd
import numpy as np

data = sns.load_dataset('iris')
data

from scipy.stats import zscore
data=sns.load_dataset('iris')
df=data.copy()

z_scores = np.abs(zscore(df.drop('species',axis=1)))

z_scores

z_scores = np.abs(zscore(df.drop('species',axis=1)))
z_scores

non_outliers = (z_scores < 3).all(axis=1)
df_no_outliers = df[non_outliers]

df_no_outliers

outliers = (z_scores > 3).any(axis=1)
outlier_rows = df[outliers]
outlier_rows

from sklearn.ensemble import IsolationForest
import seaborn as sns
import pandas as pd
import numpy as np

data=sns.load_dataset('iris')

data

clf = IsolationForest(random_state=67,contamination=0.01)
clf.fit(data)

